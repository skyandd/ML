{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from MLalgorithms.decision_tree import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математическая составляющая работы алгоритма была взята мной из данной статьи:\n",
    "\n",
    "https://habr.com/ru/company/ods/blog/322534/\n",
    "\n",
    "Перед реализацие алгоритма я изучил множество источников, где была проделана таже работа, поэтому некоторые идеи могут показаться не оригинальными. Также, во время реализации, я столкнулся с некоторыми пробелам в знаниях. До этого я никогда не использовал деревья и рекурсию в своей работе. Пришлось подучить) В основном же, в теории алгоритм кажется до боли простым, а реализация пока оказалсь самой сложной. Рекоммендую разобрать, если кто с этим ещё не сталкивался.\n",
    "\n",
    "Алгоритмы дерева решений бывают разные, но в таких как ID3 и C4.5 лежит принцип жадной максимизации прироста информации. Т.е. на каждом шаге мы выбираем тот порог, при разбении по которому прирост информации будет максимальный. Далее процедура повторяется рекурсивно, пока не выполнится критерий останова (достижение максимальной глубины или минимального количество примеров в листе) или пока прирост информации не станет равным нулю или другой малой величины. Все зависит от задачи, которая перед нами стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверим работоспособность нашего алгоритма на игрушечном наборе данных. Инициализируем, обучим и сделаем предсказание**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "tree = DecisionTree()\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
